{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/14 08:29:10 WARN Utils: Your hostname, duyvan-Inspiron-5402 resolves to a loopback address: 127.0.1.1; using 10.0.130.75 instead (on interface wlp44s0)\n",
      "21/12/14 08:29:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/14 08:29:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version 3.2.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"1412_0828\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "sc = spark.sparkContext\n",
    "print(\"Spark Version \"+sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load('orders', format='csv',sep=',',schema=('orderid int, orderdate string, ordercustomerid int, orderstatus string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------------+---------------+\n",
      "|orderid|           orderdate|ordercustomerid|    orderstatus|\n",
      "+-------+--------------------+---------------+---------------+\n",
      "|      1|2013-07-25 00:00:...|          11599|         CLOSED|\n",
      "|      2|2013-07-25 00:00:...|            256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25 00:00:...|          12111|       COMPLETE|\n",
      "|      4|2013-07-25 00:00:...|           8827|         CLOSED|\n",
      "|      5|2013-07-25 00:00:...|          11318|       COMPLETE|\n",
      "+-------+--------------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderid: integer (nullable = true)\n",
      " |-- orderdate: string (nullable = true)\n",
      " |-- ordercustomerid: integer (nullable = true)\n",
      " |-- orderstatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+---------------+---------------+\n",
      "|orderid|orderdate            |ordercustomerid|orderstatus    |\n",
      "+-------+---------------------+---------------+---------------+\n",
      "|1      |2013-07-25 00:00:00.0|11599          |CLOSED         |\n",
      "|2      |2013-07-25 00:00:00.0|256            |PENDING_PAYMENT|\n",
      "|3      |2013-07-25 00:00:00.0|12111          |COMPLETE       |\n",
      "|4      |2013-07-25 00:00:00.0|8827           |CLOSED         |\n",
      "|5      |2013-07-25 00:00:00.0|11318          |COMPLETE       |\n",
      "+-------+---------------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.load('orders', format='csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.load('orders', format='csv',sep=',', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.read.load('orders', format='csv',sep=',', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+-----+---------------+\n",
      "|  1|2013-07-25 00:00:00.0|11599|         CLOSED|\n",
      "+---+---------------------+-----+---------------+\n",
      "|  2| 2013-07-25 00:00:...|  256|PENDING_PAYMENT|\n",
      "|  3| 2013-07-25 00:00:...|12111|       COMPLETE|\n",
      "|  4| 2013-07-25 00:00:...| 8827|         CLOSED|\n",
      "|  5| 2013-07-25 00:00:...|11318|       COMPLETE|\n",
      "|  6| 2013-07-25 00:00:...| 7130|       COMPLETE|\n",
      "+---+---------------------+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d03bf3c39edc02e28cf49d3bf8f464163d6d3d40f566724a9e79fe9bef03857c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
